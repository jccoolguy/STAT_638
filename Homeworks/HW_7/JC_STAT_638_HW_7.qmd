---
title: "STAT 638 HW 7"
author: "Jack Cunningham"
format: pdf
editor: visual
---

# 7.1)

a\)

The most obvious reason that $p_j$ cannot actually be a probability density for $(\theta,\Sigma)$ is that it does not depend on $\theta$.

Since $p_j$ does not depend on $\theta$, it assigns equal probability mass across the interval $(-\infty,\infty)$. So if we were to integrate over the range of all possible $\theta$ the probabilities would sum to $\infty$ and not $1$, which clearly violates a fundamental rule for probability density functions, total probability must sum to 1.

b\)

We have:

$$
p_j(\theta,\Sigma|y_{1},...y_n) \propto p_{j}(\theta,\Sigma) \times p(y_1,...,y_n|\theta,\Sigma)
$$

With our assumption that $p(y_1,...y_n|\theta,\Sigma) \sim\text{Multivariate Normal}(\theta,\Sigma)$ we have:

$$
p(y_1,...,y_n|\theta,\Sigma)\propto |\Sigma|^{-n/2} \exp\{-\frac{1}{2}\sum_{i=1}^n(y_i-\theta)^{T} \Sigma^{-1}(y_i-\theta)\}
$$

So:

$$
p_{j}(\theta,\Sigma|y_1,...,y_n) \propto | \Sigma|^{-(n+p+2)/2} \exp\{-\frac{1}{2}\sum_{i=1}^n(y_i-\theta)^{T} \Sigma^{-1}(y_i-\theta)\}
$$ For $p_J(\theta | \Sigma,y_1,...,y_n)$ we have:

$$
p_{J}(\theta|\Sigma,y_1,...,y_n) \propto \exp\{-\frac{1}{2}\sum_{i=1}^n(y_i-\theta)^{T} \Sigma^{-1}(y_i-\theta)\}
$$

This is clearly the $\text{Multivariate Normal}(\bar{y}, \frac{1}{n}\Sigma)$ distribution, any effect from the prior is ignored because it does not depend on $\theta$.

For $p_{j}(\Sigma|y_1,...,y_n)$ its worth noticing that the prior $p_{j}(\Sigma)$ is $\text{inverse - Wishart}(1,0)$. Then we use the general result that was worked through in chapter 7:

$$
p_j(\Sigma|y_1,...,y_n) \sim \text{inverse-Wishart}(\nu_0+n,[S_{0}+S_{\theta}]^{-1})=\text{inverse-Wishart}(1+n,S_{\theta}^{-1})
$$ Where $S_{\theta}=\sum_{i=1}^n (y_i-\theta)(y_i-\theta)^{T}$.

# 7.3)

Loading data:

```{r}
blue_crab = read.table("bluecrab.dat")
blue_crab = data.frame(depth = blue_crab$V1, width = blue_crab$V2)

orange_crab = read.table("orangecrab.dat")
orange_crab = data.frame(depth = orange_crab$V1, width = orange_crab$V2)

head(blue_crab);head(orange_crab)
```

Obtaining Posterior Distribution:

```{r}
library(mvtnorm)
#priors
mu_blue   = colMeans(blue_crab); mu_orange = colMeans(orange_crab)
lambda_blue_0 = S_blue_0 = cov(blue_crab)
lambda_orange_0 = S_orange_0 = cov(orange_crab)
nu_0 = 4
n    = 50
theta_blue <- theta_orange <- matrix(0, nrow = 10000,ncol = 2)

sigma_blue <- theta_orange <- sigma_orange <- matrix(nrow = 10000, ncol = 4)

set.seed(10)
for(s in 1:10000){
  #theta
  Ln_blue <- solve(solve(lambda_blue_0) + n*solve(S_blue_0))
  mun_blue <- Ln_blue %*% (solve(lambda_blue_0)%*%mu_blue + 
                             n*solve(S_blue_0)%*% mu_blue)
  theta_blue[s,] <- rmvnorm(1, mun_blue, Ln_blue)
  
  Ln_orange <- solve(solve(lambda_orange_0) + n*solve(S_orange_0))
  mun_orange <- Ln_orange %*% (solve(lambda_orange_0)%*%mu_orange + 
                                 n*solve(S_orange_0) %*% mu_orange)
  theta_orange[s,] <- rmvnorm(1, mun_orange, Ln_orange)
  
  #Sigma
  Sn_blue <- S_blue_0 + 
    (t(blue_crab) - theta_blue[s])%*% t(t(blue_crab) - theta_blue[s])
  sigma_blue[s,] <- c(Sn_blue)
  
  Sn_orange <- S_orange_0 + 
    (t(orange_crab) - theta_orange[s])%*% t(t(orange_crab) - theta_orange[s])
  sigma_orange[s,] <- c(Sn_orange)

}
```

b\)

```{r, fig.width=10, fig.height=10}
par(mfrow = c(1,2))

plot(theta_blue[,1],theta_blue[,2],
     main = "Blue Crabs", xlab = "Theta 1", ylab = "Theta 2")

plot(theta_orange[,1],theta_orange[,2],
     main = "Orange Crabs", xlab = "Theta 1", ylab = "Theta 2")
```

The relationship between depth and width is similar in both groups, it is tighter for orange crabs however. Both groups have similar levels of depth, but orange crabs are generally wider.

c\)

```{r}
par(mfrow = c(1,2))
rho_blue = sigma_blue[,2]/sqrt(sigma_blue[,1]*sigma_blue[,4])
rho_orange = sigma_orange[,2]/sqrt(sigma_orange[,1]*sigma_orange[,4])
plot(density(rho_blue),
     main = "Rho Blue")
plot(density(rho_orange),
     main = "Rho Orange")
```

The correlation is higher for the blue crabs as it is centered at .875 while it is centered at .775 for orange crabs. The distributions appear very similar outside of that shift.

```{r}
p_blue_lt_orange <- mean(rho_blue < rho_orange)
p_blue_lt_orange
```

The probability that $\rho_{\text{blue}}<\rho_{\text{orange}}$ is `r p_blue_lt_orange`. The results suggest that the correlation between depth and width is stronger in the blue crabs.

# 7.4)

a\)

We can use:

$$
\theta|y_1,...,y_n,\Sigma \sim \text{Multivariate Normal(}\mu_n,\Lambda_n)
$$

$$
\Sigma|y_1,...,y_n,\theta \sim \text{inverse -Wishart(}\nu_n,S_{n}^{-1})
$$

Where $\Lambda_n=(\Lambda_0^{-1}+n \Sigma^{-1})^{-1},\mu_n =(\Lambda_0^{-1}+n \Sigma^{-1})^{-1}(\Lambda_{0}^{-1} \mu_0+n \Sigma^{-1} \bar{y}).\nu_n=\nu_0+n,S_{n}=S_0+S_\theta$.

I'd assume that $\mu=(32,28)$ representing the belief that men are generally a bit older when they get married.

For $\Sigma$ I am less sure. I think a feasible range for men is $(20,44)$ so I choose a variance of 36, a feasible range for women might be a bit narrower so like $(22,34)$, so I choose a variance of 9. I expect that the ages would be quite correlated, so I choose $\rho=.7$. That would leave us with $\Sigma=\begin{bmatrix} 36 & 12.6 \\ 12.6 & 9\end{bmatrix}$.

b\)

```{r}
mu_0 <- c(32,28)
nu_0 <- 50
sd_m <- 6
sd_w <- 3
corr <- .7
sigma_mean <- matrix(c(sd_m^2,corr*sd_m*sd_w,corr*sd_m*sd_w,sd_w^2),
                     ncol = 2)
psi <- sigma_mean*(nu_0 - 2 - 1)

```

```{r, fig.width= 10, fig.height=10}
set.seed(12)
n <- 100
num_datasets <- 4
library(MASS)
library(MCMCpack)
par(mfrow = c(2,2))
for(i in 1:num_datasets){
  #Sigma Sample
  sigma <- riwish(v = nu_0, S = psi)
  
  #Theta Sample
  theta <- mvrnorm(1, mu = mu_0, Sigma = sigma)
  
  #Drawing sample from distribution
  y <- mvrnorm(n, mu = theta, Sigma = sigma)
  
  plot(y[,1],y[,2],
       xlab = "Age of Husband",
       ylab = "Age of Wife",
       xlim = c(10,80),
       ylim = c(10,80))
}
```

The distributions generally look good, but we can see that the wife age in the top right plot seems quite low. To remedy this I change $\rho=.8$ and increase the mean age of the wife to 30.

```{r}
mu_0 <- c(32,30)
nu_0 <- 50
sd_m <- 6
sd_w <- 3
corr <- .8
sigma_mean <- matrix(c(sd_m^2,corr*sd_m*sd_w,corr*sd_m*sd_w,sd_w^2),
                     ncol = 2)
psi <- sigma_mean*(nu_0 - 2 - 1)
```

```{r, fig.width= 10, fig.height=10}
set.seed(16)
n <- 100
num_datasets <- 4
library(MASS)
library(MCMCpack)
par(mfrow = c(2,2))
for(i in 1:num_datasets){
  #Sigma Sample
  sigma <- riwish(v = nu_0, S = psi)
  
  #Theta Sample
  theta <- mvrnorm(1, mu = mu_0, Sigma = sigma)
  
  #Drawing sample from distribution
  y <- mvrnorm(n, mu = theta, Sigma = sigma)
  
  plot(y[,1],y[,2],
       xlab = "Age of Husband",
       ylab = "Age of Wife",
       xlim = c(10,80),
       ylim = c(10,80))
}
```

This looks closer to my beliefs.

c\)

```{r}
agehw <- read.table("agehw.dat", header = TRUE)
```

```{r,cache=TRUE}
set.seed(15)
n <- dim(agehw)[1];theta_bar <- apply(agehw,2,mean)
L0 <- diag(2)*1
S0 <- sigma_mean
sigma <- cov(agehw)
THETA <- SIGMA <- NULL
set.seed(1)
for(s in 1:5000){
  #theta update
  Ln <- solve(solve(L0) + n*solve(sigma))
  mun <- Ln %*%( solve(L0) %*% mu_0 + n * solve(sigma) %*% theta_bar)
  theta <- rmvnorm(1, mean = c(mun), sigma = Ln)
  #Sigma update
  diff <- t(agehw) - c(theta)
  Sn <- S0 + diff %*% t(diff)
  sigma <- solve(rwish(nu_0 + n, solve(Sn)))
  #Saving
  THETA <- rbind(THETA, theta)
  SIGMA <- rbind(SIGMA, c(sigma))
}
CORR <- SIGMA[,2]/sqrt(SIGMA[,1]*SIGMA[,4])
```

```{r,fig.height=14}
par(mfrow = c(3,1))
plot(density(THETA[,1]))
plot(density(THETA[,2]))
plot(density(CORR))
```

```{r}
theta_CIs <- apply(THETA, 2, quantile, probs = c(0.025, 0.975))
CORR_CI <- quantile(CORR, c(0.025, 0.975))
cat("\n95% credible intervals for theta:\n")
print(round(theta_CIs, 3))
cat("95% CI for correlation:", round(CORR_CI, 3), "\n")
```

d\)

i\.

```{r}
set.seed(25)
n <- dim(agehw)[1];theta_bar <- apply(agehw,2,mean)
S0 <- matrix(0,2,2)
nu_0 = 0
sigma <- cov(agehw)
THETA <- SIGMA <- NULL
for(s in 1:5000){
  #theta update
  theta <- rmvnorm(1, mean = theta_bar, sigma = sigma/n)
  #Sigma update
  diff <- t(agehw) - c(theta)
  Sn <- S0 + diff %*% t(diff)
  sigma <- solve(rwish(nu_0 + n, solve(Sn)))
  #Saving
  THETA <- rbind(THETA, theta)
  SIGMA <- rbind(SIGMA, c(sigma))
}
CORR <- SIGMA[,2]/sqrt(SIGMA[,1]*SIGMA[,4])
```

```{r}
theta_CIs <- apply(THETA, 2, quantile, probs = c(0.025, 0.975))
CORR_CI <- quantile(CORR, c(0.025, 0.975))
cat("\n95% credible intervals for theta:\n")
print(round(theta_CIs, 3))
cat("95% CI for correlation:", round(CORR_CI, 3), "\n")
```

ii\.

```{r}
set.seed(30)
n <- dim(agehw)[1];theta_bar <- apply(agehw,2,mean)
L0 <- cov(agehw)
S0 <- cov(agehw)
nu_0 = 4
mu_0 = theta_bar
sigma <- cov(agehw)
THETA <- SIGMA <- NULL
for(s in 1:5000){
  #theta update
  Ln <- solve(solve(L0) + n*solve(sigma))
  mun <- Ln %*%( solve(L0) %*% mu_0 + n * solve(sigma) %*% theta_bar)
  theta <- rmvnorm(1, mean = c(mun), sigma = Ln)
  #Sigma update
  diff <- t(agehw) - c(theta)
  Sn <- S0 + diff %*% t(diff)
  sigma <- solve(rwish(nu_0 + n, solve(Sn)))
  #Saving
  THETA <- rbind(THETA, theta)
  SIGMA <- rbind(SIGMA, c(sigma))
}
CORR <- SIGMA[,2]/sqrt(SIGMA[,1]*SIGMA[,4])
```

```{r}
theta_CIs <- apply(THETA, 2, quantile, probs = c(0.025, 0.975))
CORR_CI <- quantile(CORR, c(0.025, 0.975))
cat("\n95% credible intervals for theta:\n")
print(round(theta_CIs, 3))
cat("95% CI for correlation:", round(CORR_CI, 3), "\n")
```

iii\.

```{r, cache=TRUE}
set.seed(20)
n <- dim(agehw)[1];theta_bar <- apply(agehw,2,mean)
L0 <- diag(2)*10^5
S0 <- diag(2)*1000
nu_0 = 3
mu_0 = c(0,0)
sigma <- cov(agehw)
THETA <- SIGMA <- NULL
for(s in 1:5000){
  #theta update
  Ln <- solve(solve(L0) + n*solve(sigma))
  mun <- Ln %*%( solve(L0) %*% mu_0 + n * solve(sigma) %*% theta_bar)
  theta <- rmvnorm(1, mean = c(mun), sigma = Ln)
  #Sigma update
  diff <- t(agehw) - c(theta)
  Sn <- S0 + diff %*% t(diff)
  sigma <- solve(rwish(nu_0 + n, solve(Sn)))
  #Saving
  THETA <- rbind(THETA, theta)
  SIGMA <- rbind(SIGMA, c(sigma))
}
CORR <- SIGMA[,2]/sqrt(SIGMA[,1]*SIGMA[,4])
```

```{r}
theta_CIs <- apply(THETA, 2, quantile, probs = c(0.025, 0.975))
CORR_CI <- quantile(CORR, c(0.025, 0.975))
cat("\n95% credible intervals for theta:\n")
print(round(theta_CIs, 3))
cat("95% CI for correlation:", round(CORR_CI, 3), "\n")
```

e\)

The confidence intervals for $\theta$ are extremely similar to each other in part d, they are quite different from my strong prior in part c. I severely underestimated the ages for both groups. The correlation intervals are all pretty similar however.

My prior information was not helpful because it was not a good estimate of reality it seems, I was way off. Instead I would use the Jeffrey's prior to reflect that I do not have a prior information to add to the problem.

If n was smaller I'd consider doing some research to get a reasonable prior to center $\mu$ , but I would avoid making it too strong.
